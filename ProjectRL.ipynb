{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import gym_maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [ 20,  20, 159],\n",
       "        [ 20,  20, 159],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [ 20,  20, 159],\n",
       "        [ 20,  20, 159],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [159,  20,  20],\n",
       "        [159,  20,  20],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [159,  20,  20],\n",
       "        [159,  20,  20],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"maze-random-10x10-v0\")\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.reset()\n",
    "\n",
    "# for _ in range(1000):\n",
    "#     env.render()\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " L _ _ _ _ _ _ _ _ _ \n",
      "_ _ _ _ _ _ _ _ _ _ \n",
      "_ # _ _ _ _ _ _ _ _ \n",
      "_ _ $ _ _ _ _ _ _ _ \n",
      "_ _ _ _ _ _ _ _ _ _ \n",
      "_ _ _ _ _ _ _ _ _ _ \n",
      "_ _ _ _ _ _ _ _ _ _ \n",
      "_ _ _ _ _ _ _ _ _ _ \n",
      "_ _ _ _ _ _ _ _ _ _ \n",
      "_ _ _ _ _ _ _ _ _ _ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def init_env():\n",
    "    start = (0,0)\n",
    "    terminal = (3,2)\n",
    "    hole = (2,1)\n",
    "    env = np.array([[\"_ \"]*10]*10)\n",
    "    env[terminal] = \"$ \"\n",
    "    env[hole] = \"# \"\n",
    "    env[start] = \"L \"\n",
    "    interaction = \" \"\n",
    "\n",
    "    for i in env:\n",
    "        interaction += \"\".join(i) + \"\\n\"\n",
    "    print(interaction)\n",
    "\n",
    "init_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_q_table():\n",
    "    #Q-Table\n",
    "    actions = np.array(['up', 'down', 'left', 'right'])\n",
    "    q_table = pd.DataFrame(\n",
    "        np.zeros((100, len(actions))), columns = actions\n",
    "    )\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_choose(state, q_table, epsilon):\n",
    "    '''\n",
    "    state\n",
    "    q_table\n",
    "    epsilon\n",
    "\n",
    "    action\n",
    "    '''\n",
    "\n",
    "    state_act = q_table.iloc[state, :]\n",
    "    actions = np.array(['up', 'down', 'left', 'right'])\n",
    "\n",
    "    if np.random.uniform() > epsilon or state_act.all() == 0:\n",
    "        action = np.random.choice(actions)\n",
    "    else:\n",
    "        action = state_act.idxmax()\n",
    "    return action \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_feedback(state, action, hole, terminal):\n",
    "    reward = 0.0\n",
    "    end = 0 \n",
    "\n",
    "    a,b = state\n",
    "    \n",
    "    if action == \"up\":\n",
    "        a -= 1\n",
    "        if a < 0:\n",
    "            a = 0\n",
    "        next_state = (a, b)\n",
    "    elif action == \"down\":\n",
    "        a += 1\n",
    "        if a >= 4:\n",
    "            a = 3\n",
    "        next_state = (a, b)\n",
    "    elif action == \"left\":\n",
    "        b -=1\n",
    "        if b < 0:\n",
    "            b = 0\n",
    "        next_state = (a, b)\n",
    "    elif action == \"right\":\n",
    "        b += 1\n",
    "        if b >= 4:\n",
    "            b = 3\n",
    "        next_state = (a,b)\n",
    "\n",
    "    if next_state == terminal:\n",
    "        reward = 10.0\n",
    "        end = 2\n",
    "    elif next_state == hole:\n",
    "        reward = -10.0\n",
    "        end = 1\n",
    "    else:\n",
    "        reward = -1.0\n",
    "    return next_state, reward, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q_table(q_table, state, action, next_state, terminal, gamma, alpha, reward):\n",
    "    x, y = state \n",
    "    next_x, next_y = next_state \n",
    "    q_original = q_table.loc[x * 4 + y, action] \n",
    "    if next_state != terminal: \n",
    "        q_predict = reward + gamma * q_table.iloc[next_x * 4 + next_y].max()\n",
    "    else:\n",
    "        q_predict = reward \n",
    "        \n",
    "    q_table.loc[x * 4 + y, action] = (1 - alpha) * q_original + alpha * q_predict\n",
    "    \n",
    "    return q_table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(end, state, episodes, step, q_table):\n",
    "    # Your implementation to visualize or print the state\n",
    "    print(f\"End: {end}, State: {state}, Episodes: {episodes}, Steps: {step}, Q-table: {q_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(max_episodes, alpha, gamma, epsilon): \n",
    "    q_table = init_q_table() \n",
    "    terminal = (3, 2) \n",
    "    hole = (2, 1) \n",
    "    episodes = 0 \n",
    "    step = 0\n",
    "    \n",
    "    while episodes <= max_episodes: \n",
    "        slep = 0 \n",
    "        state = (0, 0) \n",
    "        end = 0 \n",
    "        show_state(end, state, episodes, step, q_table) \n",
    "\n",
    "        while end == 0: \n",
    "            x, y = state \n",
    "            act = act_choose(x * 4 + y, q_table, epsilon) \n",
    "            next_state, reward, end = env_feedback(state, act, hole, terminal) \n",
    "            q_table = update_q_table( \n",
    "                q_table, state, act, next_state, terminal, gamma, alpha, reward \n",
    "                ) #q-table \n",
    "            state = next_state \n",
    "            step += 1 \n",
    "            show_state(end, state, episodes, step, q_table) \n",
    "        if end == 2: \n",
    "            episodes += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
